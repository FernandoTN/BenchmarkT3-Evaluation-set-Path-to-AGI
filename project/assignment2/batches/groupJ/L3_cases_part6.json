[
  {
    "case_id": "T3-J1-L3-0055",
    "pearl_level": "L3",
    "domain": "D10",
    "subdomain": "Intelligence Analysis",
    "difficulty": "Hard",
    "trap_type": "F6",
    "trap_family": "F6",
    "trap_subtype": "Hindsight Bias",
    "scenario": "Intelligence agencies failed to predict a terrorist attack despite having fragmentary information that, in retrospect, pointed to the plot. Post-attack analysis identified clear warning signs that were not recognized beforehand.",
    "counterfactual_claim": "If analysts had connected the available information, they would have predicted the attack",
    "variables": {
      "X": {"name": "Information synthesis", "role": "Antecedent"},
      "Y": {"name": "Attack prediction", "role": "Consequent"},
      "Z": {"name": "Pre-attack information context", "role": "Epistemic condition"}
    },
    "invariants": ["Same raw intelligence", "Same analytical resources", "Same threat environment"],
    "ground_truth": "CONDITIONAL",
    "label": "CONDITIONAL",
    "justification": "Hindsight makes the relevant signals obvious, but ex ante they were embedded in noise. The counterfactual requires evaluating what was knowable given the information context, not what is obvious in retrospect.",
    "wise_refusal": "This counterfactual suffers from hindsight bias. Whether the information could have been connected requires evaluating the signal-to-noise ratio as it appeared before the attack, not after.",
    "key_insight": "Hindsight bias inflates the apparent predictability of events, invalidating naive counterfactuals about prevention.",
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 9.0
  },
  {
    "case_id": "T3-J1-L3-0056",
    "pearl_level": "L3",
    "domain": "D10",
    "subdomain": "Economic Forecasting",
    "difficulty": "Medium",
    "trap_type": "F6",
    "trap_family": "F6",
    "trap_subtype": "Epistemic Uncertainty",
    "scenario": "A central bank raised interest rates in 2022 to combat inflation. Inflation subsequently decreased, but the economy also entered recession. Economists debate whether rates were raised too much or too little.",
    "counterfactual_claim": "If the central bank had raised rates less aggressively, inflation would have decreased without causing recession",
    "variables": {
      "X": {"name": "Interest rate policy", "role": "Antecedent"},
      "Y": {"name": "Inflation and growth outcomes", "role": "Consequent"},
      "Z": {"name": "Economic model uncertainty", "role": "Epistemic condition"}
    },
    "invariants": ["Same supply shocks", "Same fiscal policy", "Same global conditions"],
    "ground_truth": "CONDITIONAL",
    "label": "CONDITIONAL",
    "justification": "Economic models disagree on the inflation-output tradeoff. The counterfactual depends on which model is correct about monetary transmission mechanisms, which remains empirically contested.",
    "wise_refusal": "This counterfactual depends on contested economic models. Different theories predict different outcomes from alternative rate paths, and the true model is uncertain.",
    "key_insight": "Model uncertainty in economics makes policy counterfactuals inherently contested.",
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.5
  },
  {
    "case_id": "T3-J1-L3-0057",
    "pearl_level": "L3",
    "domain": "D10",
    "subdomain": "Historical Analysis",
    "difficulty": "Hard",
    "trap_type": "F6",
    "trap_family": "F6",
    "trap_subtype": "Counterfactual Epistemology",
    "scenario": "Historians debate whether World War I could have been prevented through different diplomacy. The actual chain of events involved multiple decision points where alternative choices might have avoided war.",
    "counterfactual_claim": "If Austria-Hungary had accepted Serbia's conciliatory response to the ultimatum, World War I would not have occurred",
    "variables": {
      "X": {"name": "Austrian diplomatic response", "role": "Antecedent"},
      "Y": {"name": "War occurrence", "role": "Consequent"},
      "Z": {"name": "Underlying tensions and alliances", "role": "Context"}
    },
    "invariants": ["Same alliance structure", "Same nationalist tensions", "Same military planning"],
    "ground_truth": "CONDITIONAL",
    "label": "CONDITIONAL",
    "justification": "Historical counterfactuals involve deep uncertainty. The underlying tensions might have produced war through other triggers. The claim requires assumptions about whether this specific trigger was necessary or merely precipitating.",
    "wise_refusal": "This counterfactual depends on whether WWI was overdetermined by structural factors or contingent on specific diplomatic choices. Historians disagree on this fundamental question.",
    "key_insight": "Historical counterfactuals require distinguishing necessary causes from precipitating events in complex systems.",
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 9.0
  },
  {
    "case_id": "T3-J1-L3-0058",
    "pearl_level": "L3",
    "domain": "D10",
    "subdomain": "Survey Research",
    "difficulty": "Easy",
    "trap_type": "F6",
    "trap_family": "F6",
    "trap_subtype": "Measurement Uncertainty",
    "scenario": "A poll found that 52% of voters supported a policy, with a margin of error of plus or minus 3%. The policy was implemented. Critics claimed the poll showed majority opposition within the margin of error.",
    "counterfactual_claim": "If the poll had shown 49% support, the policy would not have been implemented",
    "variables": {
      "X": {"name": "Poll result", "role": "Antecedent"},
      "Y": {"name": "Policy implementation", "role": "Consequent"},
      "Z": {"name": "Margin of error", "role": "Epistemic condition"}
    },
    "invariants": ["Same actual public opinion", "Same political context", "Same advocacy efforts"],
    "ground_truth": "CONDITIONAL",
    "label": "CONDITIONAL",
    "justification": "The poll result is a noisy measurement of actual opinion. A 49% result could reflect the same underlying opinion as 52% given measurement error. The counterfactual about policy depends on whether officials responded to the specific number or underlying support.",
    "wise_refusal": "This counterfactual conflates the measurement with the underlying reality. Policy decisions based on polls within margin of error involve epistemic uncertainty about actual support.",
    "key_insight": "Measurement uncertainty means alternative measurements might not reflect different underlying realities.",
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.5
  },
  {
    "case_id": "T3-J1-L3-0059",
    "pearl_level": "L3",
    "domain": "D10",
    "subdomain": "Medical Decision-Making",
    "difficulty": "Medium",
    "trap_type": "F6",
    "trap_family": "F6",
    "trap_subtype": "Diagnostic Uncertainty",
    "scenario": "A doctor diagnosed a patient with a rare disease based on ambiguous symptoms. Treatment was successful. Review suggested another diagnosis was equally consistent with initial symptoms but would have required different treatment.",
    "counterfactual_claim": "If the doctor had diagnosed the alternative condition, the patient would have received inappropriate treatment",
    "variables": {
      "X": {"name": "Diagnostic choice", "role": "Antecedent"},
      "Y": {"name": "Treatment appropriateness", "role": "Consequent"},
      "Z": {"name": "Symptom ambiguity", "role": "Epistemic condition"}
    },
    "invariants": ["Same initial symptoms", "Same diagnostic tools", "Same treatment protocols"],
    "ground_truth": "VALID",
    "label": "VALID",
    "justification": "Given the actual disease (revealed by successful treatment), the alternative diagnosis would have led to inappropriate treatment. The counterfactual is valid because we now know which diagnosis was correct.",
    "wise_refusal": "This counterfactual is valid ex post because the successful treatment confirms the correct diagnosis. The alternative path would have led to treatment-disease mismatch.",
    "key_insight": "Outcome revelation can resolve ex ante diagnostic uncertainty, validating counterfactuals about alternative decisions.",
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.5
  },
  {
    "case_id": "T3-J1-L3-0060",
    "pearl_level": "L3",
    "domain": "D10",
    "subdomain": "Risk Assessment",
    "difficulty": "Hard",
    "trap_type": "F6",
    "trap_family": "F6",
    "trap_subtype": "Unknown Unknowns",
    "scenario": "Financial regulators approved a new derivative product in 2006 after risk assessment. The product contributed to the 2008 financial crisis. The risk models did not account for correlated default events that emerged.",
    "counterfactual_claim": "If regulators had known about correlated default risks, they would not have approved the product",
    "variables": {
      "X": {"name": "Risk knowledge", "role": "Antecedent"},
      "Y": {"name": "Regulatory approval", "role": "Consequent"},
      "Z": {"name": "Unknown correlation risks", "role": "Epistemic condition"}
    },
    "invariants": ["Same regulatory framework", "Same risk tolerance", "Same market demands"],
    "ground_truth": "CONDITIONAL",
    "label": "CONDITIONAL",
    "justification": "Even with known risks, regulatory decisions involve tradeoffs. The counterfactual assumes knowledge would have changed decisions, but regulators might have approved with conditions or relied on market discipline.",
    "wise_refusal": "This counterfactual assumes perfect knowledge would have led to rejection, but regulatory decisions involve weighing risks against benefits. Additional knowledge might have modified rather than prevented approval.",
    "key_insight": "Unknown unknowns complicate counterfactuals because we cannot assume how knowledge would have changed decisions.",
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 9.0
  },
  {
    "case_id": "T3-J1-L3-0061",
    "pearl_level": "L3",
    "domain": "D10",
    "subdomain": "Legal Evidence",
    "difficulty": "Medium",
    "trap_type": "F6",
    "trap_family": "F6",
    "trap_subtype": "Evidence Incompleteness",
    "scenario": "A defendant was convicted based on circumstantial evidence. Years later, new DNA evidence emerged that was not available at trial. The conviction was overturned. Critics argue the original jury made the correct decision given available evidence.",
    "counterfactual_claim": "If the DNA evidence had been available at trial, the jury would have acquitted",
    "variables": {
      "X": {"name": "DNA evidence availability", "role": "Antecedent"},
      "Y": {"name": "Trial verdict", "role": "Consequent"},
      "Z": {"name": "Evidence completeness", "role": "Epistemic condition"}
    },
    "invariants": ["Same jury", "Same other evidence", "Same legal standards"],
    "ground_truth": "VALID",
    "label": "VALID",
    "justification": "The DNA evidence was exculpatory and would have changed the evidentiary balance. Given the same jury and legal standards, the additional evidence would have created reasonable doubt.",
    "wise_refusal": "This counterfactual is valid because the DNA evidence directly addresses guilt. Its inclusion would have materially changed the evidence available for jury deliberation.",
    "key_insight": "Exculpatory evidence counterfactuals are valid when the evidence directly addresses the key factual question.",
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.5
  },
  {
    "case_id": "T3-J1-L3-0062",
    "pearl_level": "L3",
    "domain": "D10",
    "subdomain": "Scientific Discovery",
    "difficulty": "Hard",
    "trap_type": "F6",
    "trap_family": "F6",
    "trap_subtype": "Discovery Contingency",
    "scenario": "A scientist discovered a breakthrough treatment through serendipity while researching an unrelated topic. The discovery required specific expertise and research infrastructure that few laboratories possessed.",
    "counterfactual_claim": "If this scientist had not made the discovery, someone else would have discovered it within a few years",
    "variables": {
      "X": {"name": "Specific scientist's discovery", "role": "Antecedent"},
      "Y": {"name": "Treatment discovery timing", "role": "Consequent"},
      "Z": {"name": "Research landscape and serendipity", "role": "Epistemic condition"}
    },
    "invariants": ["Same research funding", "Same scientific knowledge base", "Same disease burden"],
    "ground_truth": "CONDITIONAL",
    "label": "CONDITIONAL",
    "justification": "Scientific discovery involves both systematic search and serendipity. Whether another scientist would have made the same serendipitous discovery depends on assumptions about the research landscape and probability of independent discovery.",
    "wise_refusal": "This counterfactual depends on the structure of scientific discovery. Serendipitous findings may not have been inevitable, while systematic discoveries are more likely to be replicated independently.",
    "key_insight": "Counterfactuals about serendipitous discoveries require assumptions about the probability structure of research.",
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 9.0
  },
  {
    "case_id": "T3-J1-L3-0063",
    "pearl_level": "L3",
    "domain": "D10",
    "subdomain": "Public Opinion",
    "difficulty": "Easy",
    "trap_type": "F6",
    "trap_family": "F6",
    "trap_subtype": "Belief vs Reality",
    "scenario": "A community believed a factory was causing cancer based on anecdotal reports. An epidemiological study found no elevated cancer rates compared to similar communities. The factory was shut down due to public pressure.",
    "counterfactual_claim": "If the community had known the study results before acting, they would not have demanded the factory closure",
    "variables": {
      "X": {"name": "Knowledge of study results", "role": "Antecedent"},
      "Y": {"name": "Factory closure demand", "role": "Consequent"},
      "Z": {"name": "Belief-action relationship", "role": "Epistemic condition"}
    },
    "invariants": ["Same community composition", "Same anecdotal reports", "Same distrust of industry"],
    "ground_truth": "CONDITIONAL",
    "label": "CONDITIONAL",
    "justification": "Community responses depend on trust in evidence sources. The study might have been dismissed as industry-influenced. The counterfactual assumes study results would have changed beliefs, which requires assumptions about epistemic trust.",
    "wise_refusal": "This counterfactual assumes scientific evidence would override community beliefs. If distrust of official sources is strong, evidence may not change attitudes or behavior.",
    "key_insight": "Epistemic trust mediates whether evidence changes beliefs and subsequent actions.",
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.5
  },
  {
    "case_id": "T3-J1-L3-0064",
    "pearl_level": "L3",
    "domain": "D10",
    "subdomain": "Policy Evaluation",
    "difficulty": "Medium",
    "trap_type": "F6",
    "trap_family": "F6",
    "trap_subtype": "Observational Limits",
    "scenario": "A study compared outcomes in states that did and did not implement a policy. The implementing states had better outcomes, but they also differed in demographics, economics, and political culture.",
    "counterfactual_claim": "If the non-implementing states had adopted the policy, they would have achieved the same outcomes as implementing states",
    "variables": {
      "X": {"name": "Policy adoption", "role": "Antecedent"},
      "Y": {"name": "State outcomes", "role": "Consequent"},
      "Z": {"name": "Unobserved state differences", "role": "Epistemic condition"}
    },
    "invariants": ["Same policy implementation", "Same time period", "Same national context"],
    "ground_truth": "CONDITIONAL",
    "label": "CONDITIONAL",
    "justification": "The observational comparison cannot establish causation due to selection and confounding. States that adopted the policy may have done so because of characteristics that also caused better outcomes.",
    "wise_refusal": "This counterfactual requires the strong assumption that state differences do not confound the policy-outcome relationship. Unobserved heterogeneity makes this claim epistemically uncertain.",
    "key_insight": "Observational studies have inherent limits for supporting counterfactual claims about policy effects.",
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.5
  },
  {
    "case_id": "T3-J1-L3-0065",
    "pearl_level": "L3",
    "domain": "D10",
    "subdomain": "Forecasting",
    "difficulty": "Medium",
    "trap_type": "F6",
    "trap_family": "F6",
    "trap_subtype": "Prediction vs Explanation",
    "scenario": "A model accurately predicted election outcomes but could not explain why voters made their choices. The model used machine learning on social media data without interpretable features.",
    "counterfactual_claim": "If the campaign had changed its social media strategy, the model would have predicted different outcomes",
    "variables": {
      "X": {"name": "Campaign strategy", "role": "Antecedent"},
      "Y": {"name": "Model prediction", "role": "Consequent"},
      "Z": {"name": "Model interpretability", "role": "Epistemic condition"}
    },
    "invariants": ["Same model", "Same other campaign factors", "Same voter base"],
    "ground_truth": "CONDITIONAL",
    "label": "CONDITIONAL",
    "justification": "Predictive accuracy does not guarantee causal understanding. The model may be capturing correlates of outcomes rather than causes. Strategy changes might not affect outcomes as the model would suggest.",
    "wise_refusal": "This counterfactual conflates prediction with causal mechanism. The model's accuracy for prediction does not establish that interventions on predicted features would change outcomes.",
    "key_insight": "Predictive models do not necessarily support causal counterfactuals without understanding mechanisms.",
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.5
  },
  {
    "case_id": "T3-J1-L3-0066",
    "pearl_level": "L3",
    "domain": "D10",
    "subdomain": "Organizational Learning",
    "difficulty": "Easy",
    "trap_type": "F6",
    "trap_family": "F6",
    "trap_subtype": "Learning from Failure",
    "scenario": "A startup failed after pivoting away from its original product. Post-mortem analysis suggested the pivot was premature and the original product might have succeeded with more time.",
    "counterfactual_claim": "If the startup had not pivoted, it would have succeeded",
    "variables": {
      "X": {"name": "Pivot decision", "role": "Antecedent"},
      "Y": {"name": "Startup success", "role": "Consequent"},
      "Z": {"name": "Unobserved alternative path", "role": "Epistemic condition"}
    },
    "invariants": ["Same market conditions", "Same team", "Same resources"],
    "ground_truth": "CONDITIONAL",
    "label": "CONDITIONAL",
    "justification": "Post-mortem analysis of failures is subject to narrative fallacy. The original product's potential success is unobserved. The counterfactual requires speculating about an unrealized path.",
    "wise_refusal": "This counterfactual involves speculation about an unobserved alternative. We cannot know whether the original product would have succeeded because that path was never taken.",
    "key_insight": "Counterfactuals about unrealized business strategies involve fundamental unobservability.",
    "initial_author": "Fernando Torres",
    "validator": "Fernando Torres",
    "final_score": 8.5
  }
]
